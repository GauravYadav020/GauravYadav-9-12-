# -*- coding: utf-8 -*-
"""DSCM21L5A1 - Churn Modelling Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bDLr5WbccFb3HF1fL-2Nk0YDRTI1QSXC
"""

!pip install -q keras

"""### **1. Import Necessary Libraries**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### **2. Import Dataset**"""

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('Churn_Modelling.csv')
df.head()

df.info()

df.describe()

"""**Conclusion -**
1. Dataset Shape - (10000, 14)
2. Numerical features - 11
3. Categorical features - 3
4. Null Values - 0

### **3. Data Preprocessing**

#### **3.1. Label Encoding**
"""

from sklearn.preprocessing import LabelEncoder
lb = LabelEncoder()

df['Geography'] = lb.fit_transform(df['Geography'])
df['Gender'] = lb.fit_transform(df['Gender'])

df

df.info()

"""#### **3.2. Feature Selection**"""

df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)

df.shape

"""#### **3.3. Train Test Split**"""

y = df.pop('Exited')
X = df

X.shape

y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

"""#### **3.4. Feature Scaling**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

X_train

"""### **4. Model Building**"""

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LeakyReLU, PReLU, ELU
from keras.layers import Dropout

#initialize the ANN
classifier = Sequential()

# Add the input layer and the first hidden layer
classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu',input_dim = 10))

# Add the second hidden layer
classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))

# Add the output layer
classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))

# Compile the ANN
classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])

# Fitting the ANN to the Training set
model_history=classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)

# list all data in history
classifier.summary()
#total params are total number of weights and biases

"""### **5. Model Evaluation**"""

# Predict the Test set results
Y_pred = classifier.predict(X_test)
Y_pred

Y_pred = (Y_pred > 0.5)

Y_pred

# Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, Y_pred)
print(cm)

# Calculate the Accuracy
from sklearn.metrics import accuracy_score
score=accuracy_score(Y_pred,y_test)

print(score)

